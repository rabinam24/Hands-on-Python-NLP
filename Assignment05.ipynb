{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "mount_file_id": "1O-EiTrg_47FA8ZRXOPtC64TcoUWTBIjX",
      "authorship_tag": "ABX9TyNqzD+tsWXjHnK4FkpIZisg",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/rabinam24/Hands-on-Python-NLP/blob/main/Assignment05.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 97,
      "metadata": {
        "id": "7rxeZBz4VcIF"
      },
      "outputs": [],
      "source": [
        "from gensim.test.utils import common_texts\n",
        "import numpy as np\n",
        "from gensim.models.doc2vec import Doc2Vec, TaggedDocument"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# pip install --upgrade gensim\n"
      ],
      "metadata": {
        "id": "E35GYV-6dCHU"
      },
      "execution_count": 48,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "common_texts"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "22Y130P0VfXw",
        "outputId": "a3458043-8081-4535-8e5d-65e786458b59"
      },
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[['human', 'interface', 'computer'],\n",
              " ['survey', 'user', 'computer', 'system', 'response', 'time'],\n",
              " ['eps', 'user', 'interface', 'system'],\n",
              " ['system', 'human', 'system', 'eps'],\n",
              " ['user', 'response', 'time'],\n",
              " ['trees'],\n",
              " ['graph', 'trees'],\n",
              " ['graph', 'minors', 'trees'],\n",
              " ['graph', 'minors', 'survey']]"
            ]
          },
          "metadata": {},
          "execution_count": 49
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "documents = [TaggedDocument(doc, [i]) for i, doc in enumerate(common_texts)]\n",
        "documents"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "W_a6GwWoViyr",
        "outputId": "39e903a4-4278-4754-b3ab-d49b94af5064"
      },
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[TaggedDocument(words=['human', 'interface', 'computer'], tags=[0]),\n",
              " TaggedDocument(words=['survey', 'user', 'computer', 'system', 'response', 'time'], tags=[1]),\n",
              " TaggedDocument(words=['eps', 'user', 'interface', 'system'], tags=[2]),\n",
              " TaggedDocument(words=['system', 'human', 'system', 'eps'], tags=[3]),\n",
              " TaggedDocument(words=['user', 'response', 'time'], tags=[4]),\n",
              " TaggedDocument(words=['trees'], tags=[5]),\n",
              " TaggedDocument(words=['graph', 'trees'], tags=[6]),\n",
              " TaggedDocument(words=['graph', 'minors', 'trees'], tags=[7]),\n",
              " TaggedDocument(words=['graph', 'minors', 'survey'], tags=[8])]"
            ]
          },
          "metadata": {},
          "execution_count": 50
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model = Doc2Vec(documents, vector_size=5, min_count=1, workers=4, epochs = 40)\n",
        "model.train(documents, total_examples=model.corpus_count, epochs=model.epochs)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3kwfiR6_VlZN",
        "outputId": "50c8ced2-0609-4a73-a2fb-4bf525c4a923"
      },
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:gensim.models.word2vec:Effective 'alpha' higher than previous training cycles\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.vector_size"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "V3B-nebhVn8w",
        "outputId": "40811f85-9ea2-42a0-c2dc-c98b7b592ae8"
      },
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "5"
            ]
          },
          "metadata": {},
          "execution_count": 52
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "len(model.dv)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hDi91GYMVqRV",
        "outputId": "8f885957-6b3d-4739-b103-a1bc2622d699"
      },
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "9"
            ]
          },
          "metadata": {},
          "execution_count": 53
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "len(model.wv.key_to_index)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZKlk7eLwVsqX",
        "outputId": "22e2eaac-999b-4a2b-e048-bcacf4e37a0d"
      },
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "12"
            ]
          },
          "metadata": {},
          "execution_count": 54
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "list(model.wv.key_to_index.keys())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6CUTF0eAVuZ6",
        "outputId": "8f92cda3-76f1-4295-d19d-2f9134ee1c23"
      },
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['system',\n",
              " 'graph',\n",
              " 'trees',\n",
              " 'user',\n",
              " 'minors',\n",
              " 'eps',\n",
              " 'time',\n",
              " 'response',\n",
              " 'survey',\n",
              " 'computer',\n",
              " 'interface',\n",
              " 'human']"
            ]
          },
          "metadata": {},
          "execution_count": 55
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "vector = model.infer_vector(['user', 'interface', 'for', 'computer'])\n",
        "print(vector)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lOquJ4WkVwFc",
        "outputId": "2d2d1616-964e-44f1-dc0d-357049a6b760"
      },
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[ 0.01429733 -0.03776683  0.07977191  0.08964317  0.09892745]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model = Doc2Vec(documents, vector_size=50, min_count=3, epochs=40)\n",
        "model.train(documents, total_examples=model.corpus_count, epochs=model.epochs)\n",
        "len(model.wv.key_to_index)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "v80YVzXnVyRr",
        "outputId": "53e53059-65a2-40ab-e02f-f60e30d0cff4"
      },
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:gensim.models.word2vec:Effective 'alpha' higher than previous training cycles\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "4"
            ]
          },
          "metadata": {},
          "execution_count": 57
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.wv.key_to_index"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qw_7dpIyV0WA",
        "outputId": "44a6fd37-4b62-4f4f-e701-bf04934fcc6d"
      },
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'system': 0, 'graph': 1, 'trees': 2, 'user': 3}"
            ]
          },
          "metadata": {},
          "execution_count": 58
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "vector = model.infer_vector(['user', 'interface', 'for', 'computer'])\n",
        "print(vector)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6h5pCxA_V2Im",
        "outputId": "cadf57f7-f707-4843-e02d-3948f217650b"
      },
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[ 0.00166606 -0.00350605  0.00859453  0.00947686  0.00978834 -0.00372925\n",
            " -0.00076591  0.00784794 -0.00724848  0.00622069 -0.00151916 -0.00307518\n",
            "  0.00081389 -0.00222157 -0.00582184 -0.00461164 -0.00757601  0.00241692\n",
            " -0.00012233  0.00888132 -0.00365807 -0.00457171  0.00066168  0.00426824\n",
            " -0.00083538  0.00409521 -0.00169888 -0.00987113  0.00536945 -0.00032667\n",
            "  0.00736014 -0.00865401  0.00558877 -0.0029462  -0.00220892 -0.00605291\n",
            " -0.00973224 -0.00250679  0.00012752 -0.00365978  0.00749419  0.00727449\n",
            " -0.00824867  0.00807471 -0.00537765 -0.00544847  0.00167216 -0.0064497\n",
            " -0.00884024 -0.0036239 ]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model = Doc2Vec(documents, vector_size=50, min_count=2, epochs=40, dm=1)\n",
        "model.train(documents, total_examples=model.corpus_count, epochs=model.epochs)\n",
        "vector = model.infer_vector(['user', 'interface', 'for', 'computer'])\n",
        "print(vector)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "u5FV22plV4di",
        "outputId": "4ed61a4d-f5bc-4ec4-e844-88817078e249"
      },
      "execution_count": 60,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:gensim.models.word2vec:Effective 'alpha' higher than previous training cycles\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[ 0.00102677 -0.00363204  0.00820568  0.00945647  0.00956765 -0.00354801\n",
            " -0.00101137  0.00830846 -0.00786253  0.00653356 -0.00119177 -0.00252815\n",
            "  0.0010458  -0.00255662 -0.00552864 -0.00514037 -0.0075631   0.00267906\n",
            " -0.0007726   0.00876697 -0.00403908 -0.00452473  0.00038007  0.00444349\n",
            " -0.00093152  0.00413464 -0.00207906 -0.01051018  0.00545054 -0.00059392\n",
            "  0.00792537 -0.00818485  0.00493663 -0.00307189 -0.00224129 -0.00562273\n",
            " -0.00986158 -0.0031014   0.00032609 -0.00373358  0.0070598   0.00770361\n",
            " -0.00843419  0.00747176 -0.00570915 -0.0051033   0.0019478  -0.0064634\n",
            " -0.00842341 -0.00378383]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model = Doc2Vec(documents, vector_size=50, min_count=2, epochs=40, dm=0)\n",
        "model.train(documents, total_examples=model.corpus_count, epochs=model.epochs)\n",
        "vector = model.infer_vector(['user', 'interface', 'for', 'computer'])\n",
        "print(vector)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BLtfpNmkV6u1",
        "outputId": "6edfd2a0-dd93-426a-eb69-cd6f9738332c"
      },
      "execution_count": 61,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:gensim.models.word2vec:Effective 'alpha' higher than previous training cycles\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[-0.00029261 -0.00385866  0.00760137  0.00911416  0.00910696 -0.00312944\n",
            " -0.00151703  0.00937205 -0.00852151  0.00733277 -0.00078267 -0.00157058\n",
            "  0.00152586 -0.00302576 -0.00479466 -0.00589519 -0.00823611  0.00285653\n",
            " -0.00141118  0.00898319 -0.00466567 -0.00447526 -0.00038184  0.00449705\n",
            " -0.00120319  0.00435987 -0.002539   -0.01167126  0.00545236 -0.00080897\n",
            "  0.00898326 -0.0071929   0.00369112 -0.00270718 -0.0024641  -0.00454054\n",
            " -0.01035296 -0.00378449  0.00065542 -0.0039516   0.00630124  0.00854271\n",
            " -0.00877623  0.00664782 -0.00677459 -0.00425875  0.00252991 -0.00629803\n",
            " -0.00773384 -0.00409126]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model = Doc2Vec(documents, vector_size=50, min_count=2, epochs=40, window=2, dm=0)\n",
        "model.train(documents, total_examples=model.corpus_count, epochs=model.epochs)\n",
        "vector = model.infer_vector(['user', 'interface', 'for', 'computer'])\n",
        "print(vector)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ANOp9yEVV8oe",
        "outputId": "971ca7f6-c97e-4abe-bca6-4e24bf1d8972"
      },
      "execution_count": 62,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:gensim.models.word2vec:Effective 'alpha' higher than previous training cycles\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[-0.00029261 -0.00385866  0.00760137  0.00911416  0.00910696 -0.00312944\n",
            " -0.00151703  0.00937205 -0.00852151  0.00733277 -0.00078267 -0.00157058\n",
            "  0.00152586 -0.00302576 -0.00479466 -0.00589519 -0.00823611  0.00285653\n",
            " -0.00141118  0.00898319 -0.00466567 -0.00447526 -0.00038184  0.00449705\n",
            " -0.00120319  0.00435987 -0.002539   -0.01167126  0.00545236 -0.00080897\n",
            "  0.00898326 -0.0071929   0.00369112 -0.00270718 -0.0024641  -0.00454054\n",
            " -0.01035296 -0.00378449  0.00065542 -0.0039516   0.00630124  0.00854271\n",
            " -0.00877623  0.00664782 -0.00677459 -0.00425875  0.00252991 -0.00629803\n",
            " -0.00773384 -0.00409126]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model = Doc2Vec(documents, vector_size=50, min_count=2, epochs=40, window=2, dm=1, alpha=0.3, min_alpha=0.05)\n",
        "model.train(documents, total_examples=model.corpus_count, epochs=model.epochs)\n",
        "vector = model.infer_vector(['user', 'interface', 'for', 'computer'])\n",
        "print(vector)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DzFcY9ICV-2p",
        "outputId": "03c05001-5c98-4dec-d522-4cd4844a963d"
      },
      "execution_count": 63,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:gensim.models.word2vec:Effective 'alpha' higher than previous training cycles\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[-3.1516230e-01 -6.7569532e-02 -1.9545291e-01  3.3224178e-03\n",
            " -1.2564132e-01  1.1452558e-01 -1.6846201e-01  1.9466634e-01\n",
            " -2.8233412e-01  1.2531410e-01  2.3572899e-01  2.6777208e-01\n",
            "  1.1934352e-01 -2.5118920e-01  1.6887721e-01 -3.5196790e-01\n",
            " -8.7952383e-02  1.3841276e-01 -3.4104630e-01 -3.1168919e-02\n",
            " -7.7198721e-02  6.5463834e-02 -1.7139183e-01  1.7124879e-01\n",
            " -4.5690037e-02  2.3278123e-04 -2.1418765e-01 -2.9841480e-01\n",
            "  6.3134417e-02 -1.9024695e-01  3.3764091e-01  2.1694344e-01\n",
            " -3.4437194e-01 -7.9851732e-02 -9.0137191e-02  1.7665286e-01\n",
            " -3.5699204e-02 -1.8551914e-01 -2.3654606e-02 -1.6458618e-02\n",
            " -1.1811650e-01  1.5085095e-01 -5.1444909e-03 -3.0692211e-01\n",
            " -7.7996254e-02  1.6315340e-01  1.8843779e-01 -1.7987365e-02\n",
            "  2.3168688e-01 -1.8081319e-01]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model = Doc2Vec(documents, vector_size=50, min_count=2, epochs=40, window=2, dm=1, alpha=0.3, min_alpha=0.05, dm_concat=1)\n",
        "model.train(documents, total_examples=model.corpus_count, epochs=model.epochs)\n",
        "vector = model.infer_vector(['user', 'interface', 'for', 'computer'])\n",
        "print(vector)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Z71yb_fVWBPD",
        "outputId": "ec36e808-d0a0-44ae-e437-86aceca4e905"
      },
      "execution_count": 64,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:gensim.models.word2vec:Effective 'alpha' higher than previous training cycles\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[ 4.6315331e-02 -2.0397307e-01 -1.0403238e-01  2.0014903e-02\n",
            "  1.6284339e-01  6.6184364e-02  2.6427813e-02 -2.5150478e-01\n",
            "  1.0975546e-03  1.7131601e-01 -1.0832633e-01 -1.3244077e-02\n",
            " -1.7636374e-01 -1.6820037e-01 -1.8947512e-02 -1.5899627e-01\n",
            "  3.4770332e-02  8.0989011e-02 -4.3561444e-02 -1.8452245e-01\n",
            "  3.2427963e-03  1.5540667e-02 -9.1181949e-02  3.2214925e-02\n",
            " -2.3768431e-01 -8.0242388e-02 -2.7134633e-01 -2.3161616e-02\n",
            "  8.1311852e-02 -1.6875944e-01  1.8636668e-01 -3.6173139e-02\n",
            "  6.8385601e-02 -2.0939265e-01  9.4124965e-02 -1.5738143e-01\n",
            "  4.9928475e-02 -1.1595362e-01 -6.5591410e-03  3.3845089e-02\n",
            "  2.1228422e-01 -1.0409037e-02  2.1502101e-01 -2.1056662e-01\n",
            "  4.2632047e-02 -8.0353633e-02  5.1191181e-02 -1.3097478e-02\n",
            "  8.9102003e-05 -1.5274315e-01]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model = Doc2Vec(documents, vector_size=50, min_count=2, epochs=40, window=2, dm=1, dm_concat=0, dm_mean=1, alpha=0.3, min_alpha=0.05)\n",
        "model.train(documents, total_examples=model.corpus_count, epochs=model.epochs)\n",
        "vector = model.infer_vector(['user', 'interface', 'for', 'computer'])\n",
        "print(vector)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sSL8XPtTWDJz",
        "outputId": "f449c3d7-e13a-462c-c639-7f893c890d55"
      },
      "execution_count": 65,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:gensim.models.word2vec:Effective 'alpha' higher than previous training cycles\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[-3.1516230e-01 -6.7569532e-02 -1.9545291e-01  3.3224178e-03\n",
            " -1.2564132e-01  1.1452558e-01 -1.6846201e-01  1.9466634e-01\n",
            " -2.8233412e-01  1.2531410e-01  2.3572899e-01  2.6777208e-01\n",
            "  1.1934352e-01 -2.5118920e-01  1.6887721e-01 -3.5196790e-01\n",
            " -8.7952383e-02  1.3841276e-01 -3.4104630e-01 -3.1168919e-02\n",
            " -7.7198721e-02  6.5463834e-02 -1.7139183e-01  1.7124879e-01\n",
            " -4.5690037e-02  2.3278123e-04 -2.1418765e-01 -2.9841480e-01\n",
            "  6.3134417e-02 -1.9024695e-01  3.3764091e-01  2.1694344e-01\n",
            " -3.4437194e-01 -7.9851732e-02 -9.0137191e-02  1.7665286e-01\n",
            " -3.5699204e-02 -1.8551914e-01 -2.3654606e-02 -1.6458618e-02\n",
            " -1.1811650e-01  1.5085095e-01 -5.1444909e-03 -3.0692211e-01\n",
            " -7.7996254e-02  1.6315340e-01  1.8843779e-01 -1.7987365e-02\n",
            "  2.3168688e-01 -1.8081319e-01]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model = Doc2Vec(documents, vector_size=50, min_count=2, epochs=40, window=2, dm=1, dm_concat=0, dm_mean=0, alpha=0.3, min_alpha=0.05)\n",
        "model.train(documents, total_examples=model.corpus_count, epochs=model.epochs)\n",
        "vector = model.infer_vector(['user', 'interface', 'for', 'computer'])\n",
        "print(vector)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "T-3HhL7RWFRK",
        "outputId": "4373d524-b8cb-4913-8984-f92621093047"
      },
      "execution_count": 66,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:gensim.models.word2vec:Effective 'alpha' higher than previous training cycles\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[-3.1516230e-01 -6.7569532e-02 -1.9545291e-01  3.3224178e-03\n",
            " -1.2564132e-01  1.1452558e-01 -1.6846201e-01  1.9466634e-01\n",
            " -2.8233412e-01  1.2531410e-01  2.3572899e-01  2.6777208e-01\n",
            "  1.1934352e-01 -2.5118920e-01  1.6887721e-01 -3.5196790e-01\n",
            " -8.7952383e-02  1.3841276e-01 -3.4104630e-01 -3.1168919e-02\n",
            " -7.7198721e-02  6.5463834e-02 -1.7139183e-01  1.7124879e-01\n",
            " -4.5690037e-02  2.3278123e-04 -2.1418765e-01 -2.9841480e-01\n",
            "  6.3134417e-02 -1.9024695e-01  3.3764091e-01  2.1694344e-01\n",
            " -3.4437194e-01 -7.9851732e-02 -9.0137191e-02  1.7665286e-01\n",
            " -3.5699204e-02 -1.8551914e-01 -2.3654606e-02 -1.6458618e-02\n",
            " -1.1811650e-01  1.5085095e-01 -5.1444909e-03 -3.0692211e-01\n",
            " -7.7996254e-02  1.6315340e-01  1.8843779e-01 -1.7987365e-02\n",
            "  2.3168688e-01 -1.8081319e-01]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from gensim.models import FastText\n",
        "from gensim.test.utils import common_texts\n",
        "common_texts"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hRUGfU5-WHWb",
        "outputId": "ee09e6d6-7abf-41fe-a8fd-0676947ef3cf"
      },
      "execution_count": 67,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[['human', 'interface', 'computer'],\n",
              " ['survey', 'user', 'computer', 'system', 'response', 'time'],\n",
              " ['eps', 'user', 'interface', 'system'],\n",
              " ['system', 'human', 'system', 'eps'],\n",
              " ['user', 'response', 'time'],\n",
              " ['trees'],\n",
              " ['graph', 'trees'],\n",
              " ['graph', 'minors', 'trees'],\n",
              " ['graph', 'minors', 'survey']]"
            ]
          },
          "metadata": {},
          "execution_count": 67
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model = FastText(vector_size=5, window=3, min_count=1)\n",
        "model.build_vocab(corpus_iterable=common_texts)\n",
        "model.train(corpus_iterable=common_texts, total_examples=len(common_texts), epochs=10)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Kx3L5jMHWJip",
        "outputId": "4808f393-af39-4178-b60b-1686fc89e2fd"
      },
      "execution_count": 68,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(36, 290)"
            ]
          },
          "metadata": {},
          "execution_count": 68
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.wv.key_to_index.keys()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ITEpfUx7WLjb",
        "outputId": "c67a713b-16a5-45b2-ab5d-28f328c67679"
      },
      "execution_count": 69,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "dict_keys(['system', 'graph', 'trees', 'user', 'minors', 'eps', 'time', 'response', 'survey', 'computer', 'interface', 'human'])"
            ]
          },
          "metadata": {},
          "execution_count": 69
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.wv['human']"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QhibH9JNWNDu",
        "outputId": "f35d3b84-0b90-46d1-d227-51d935e8e910"
      },
      "execution_count": 70,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([-0.03166137,  0.02326731,  0.01241683,  0.00036033,  0.02841445],\n",
              "      dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 70
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.wv.most_similar(positive=['computer', 'interface'], negative=['human'])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CrxZn14zWOtA",
        "outputId": "eb671524-db8a-4a0f-de1c-ad595103f848"
      },
      "execution_count": 71,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('user', 0.7968785762786865),\n",
              " ('system', 0.17462188005447388),\n",
              " ('response', 0.104334257543087),\n",
              " ('survey', 0.009604760445654392),\n",
              " ('trees', -0.07640466839075089),\n",
              " ('time', -0.1330047994852066),\n",
              " ('minors', -0.13927175104618073),\n",
              " ('eps', -0.24093686044216156),\n",
              " ('graph', -0.291752427816391)]"
            ]
          },
          "metadata": {},
          "execution_count": 71
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model = FastText(vector_size=5, window=3, min_count=1, min_n=1, max_n=5)\n",
        "model.build_vocab(corpus_iterable=common_texts)\n",
        "model.train(corpus_iterable=common_texts, total_examples=len(common_texts), epochs=10)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0aH4ZvPjWQ9W",
        "outputId": "71ff8162-6c60-479a-96a7-bb4aa48b1574"
      },
      "execution_count": 72,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(36, 290)"
            ]
          },
          "metadata": {},
          "execution_count": 72
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.wv['rubber']"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6Rd66cfUWSng",
        "outputId": "269dc073-3184-4b0f-8228-c064aca2de92"
      },
      "execution_count": 73,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([ 0.01833104, -0.02146881,  0.00600105, -0.03445042, -0.0165866 ],\n",
              "      dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 73
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.wv.most_similar(positive=['computer', 'human'], negative=['rubber'])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ljcN7XjXWUY8",
        "outputId": "32649b75-27ea-43ee-dfa7-47ce141435d1"
      },
      "execution_count": 74,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('trees', 0.795038104057312),\n",
              " ('eps', 0.7793108820915222),\n",
              " ('minors', 0.2440604716539383),\n",
              " ('time', 0.1623203009366989),\n",
              " ('user', -0.04820726439356804),\n",
              " ('graph', -0.15672056376934052),\n",
              " ('survey', -0.20417772233486176),\n",
              " ('interface', -0.3921482563018799),\n",
              " ('response', -0.6897355914115906),\n",
              " ('system', -0.8435077667236328)]"
            ]
          },
          "metadata": {},
          "execution_count": 74
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sentences_to_be_added = [[\"I\", \"am\", \"learning\", \"Natural\", \"Language\", \"Processing\"],\n",
        "                         [\"Natural\", \"Language\", \"Processing\", \"is\", \"cool\"]]\n",
        "\n",
        "# Update the vocabulary with new words\n",
        "model.build_vocab(sentences_to_be_added, update=True)\n",
        "\n",
        "# Train the model with the existing vocabulary and additional sentences\n",
        "model.train(corpus_iterable=common_texts + sentences_to_be_added, total_examples=len(common_texts) + len(sentences_to_be_added), epochs=10)\n",
        "\n",
        "# Get the updated vocabulary\n",
        "model.wv.key_to_index"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gjJGeaZuWWo7",
        "outputId": "6ec2dd97-b9e3-4a66-ea8b-a18889e3bc5d"
      },
      "execution_count": 75,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:gensim.models.word2vec:Effective 'alpha' higher than previous training cycles\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'system': 0,\n",
              " 'graph': 1,\n",
              " 'trees': 2,\n",
              " 'user': 3,\n",
              " 'minors': 4,\n",
              " 'eps': 5,\n",
              " 'time': 6,\n",
              " 'response': 7,\n",
              " 'survey': 8,\n",
              " 'computer': 9,\n",
              " 'interface': 10,\n",
              " 'human': 11,\n",
              " 'I': 12,\n",
              " 'am': 13,\n",
              " 'learning': 14,\n",
              " 'Natural': 15,\n",
              " 'Language': 16,\n",
              " 'Processing': 17,\n",
              " 'is': 18,\n",
              " 'cool': 19}"
            ]
          },
          "metadata": {},
          "execution_count": 75
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "import re\n",
        "nltk.download('stopwords')\n",
        "nltk.download('wordnet')\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.stem.porter import PorterStemmer\n",
        "from nltk.stem.snowball import SnowballStemmer\n",
        "from nltk.stem.wordnet import WordNetLemmatizer\n",
        "from gensim.models import FastText\n",
        "import io\n",
        "import collections"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1nqB3TnwWYSV",
        "outputId": "c3df784c-2ebb-400a-e871-0ece9728d9a0"
      },
      "execution_count": 76,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "words = []\n",
        "data = []\n",
        "with io.open('/content/drive/MyDrive/comments.txt', 'r', encoding='utf-8') as file:\n",
        "    for entry in file:\n",
        "        entry = entry.strip()\n",
        "        data.append(entry)\n",
        "        words.extend(entry.split())"
      ],
      "metadata": {
        "id": "akS_VUzvWanH"
      },
      "execution_count": 77,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "unique_words = []\n",
        "unique_words = collections.Counter(words)\n",
        "unique_words.most_common(10)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aRcobJTZWcq2",
        "outputId": "c33d5ba0-f45d-4a2a-eb3e-0586008731f4"
      },
      "execution_count": 78,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('the', 445892),\n",
              " ('to', 288753),\n",
              " ('of', 219279),\n",
              " ('and', 207335),\n",
              " ('a', 201765),\n",
              " ('I', 182618),\n",
              " ('is', 164602),\n",
              " ('you', 157025),\n",
              " ('that', 140495),\n",
              " ('in', 130244)]"
            ]
          },
          "metadata": {},
          "execution_count": 78
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data[:4]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_H9wuVAIWet0",
        "outputId": "b016ac88-4d60-45d0-d812-00968c202c31"
      },
      "execution_count": 79,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['\"Explanation',\n",
              " 'Why the edits made under my username Hardcore Metallica Fan were reverted? They weren\\'t vandalisms, just closure on some GAs after I voted at New York Dolls FAC. And please don\\'t remove the template from the talk page since I\\'m retired now.89.205.38.27\"',\n",
              " \"D'aww! He matches this background colour I'm seemingly stuck with. Thanks.  (talk) 21:51, January 11, 2016 (UTC)\",\n",
              " \"Hey man, I'm really not trying to edit war. It's just that this guy is constantly removing relevant information and talking to me through edits instead of my talk page. He seems to care more about the formatting than the actual info.\"]"
            ]
          },
          "metadata": {},
          "execution_count": 79
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def text_clean(corpus):\n",
        "    '''\n",
        "    Purpose : Function to keep only alphabets, digits and certain words (punctuations, qmarks, tabs etc. removed)\n",
        "\n",
        "    Input : Takes a text corpus, 'corpus' to be cleaned along with a list of words, 'keep_list', which have to be retained\n",
        "            even after the cleaning process\n",
        "\n",
        "    Output : Returns the cleaned text corpus\n",
        "\n",
        "    '''\n",
        "    cleaned_corpus = []\n",
        "    for row in corpus:\n",
        "        qs = []\n",
        "        for word in row.split():\n",
        "            p1 = re.sub(pattern='[^a-zA-Z0-9]',repl=' ',string=word)\n",
        "            p1 = p1.lower()\n",
        "            qs.append(p1)\n",
        "        cleaned_corpus.append(' '.join(qs))\n",
        "    return cleaned_corpus"
      ],
      "metadata": {
        "id": "wD1TNTUZZt-N"
      },
      "execution_count": 80,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def stopwords_removal(corpus):\n",
        "    wh_words = ['who', 'what', 'when', 'why', 'how', 'which', 'where', 'whom']\n",
        "    stop = set(stopwords.words('english'))\n",
        "    for word in wh_words:\n",
        "        stop.remove(word)\n",
        "    corpus = [[x for x in x.split() if x not in stop] for x in corpus]\n",
        "    return corpus"
      ],
      "metadata": {
        "id": "aVLuanBwZwDG"
      },
      "execution_count": 81,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def lemmatize(corpus):\n",
        "    lem = WordNetLemmatizer()\n",
        "    corpus = [[lem.lemmatize(x, pos = 'v') for x in x] for x in corpus]\n",
        "    return corpus"
      ],
      "metadata": {
        "id": "1yfdhzJtZyLh"
      },
      "execution_count": 82,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def stem(corpus, stem_type = None):\n",
        "    if stem_type == 'snowball':\n",
        "        stemmer = SnowballStemmer(language = 'english')\n",
        "        corpus = [[stemmer.stem(x) for x in x] for x in corpus]\n",
        "    else :\n",
        "        stemmer = PorterStemmer()\n",
        "        corpus = [[stemmer.stem(x) for x in x] for x in corpus]\n",
        "    return corpus"
      ],
      "metadata": {
        "id": "txepq2mKZ0ts"
      },
      "execution_count": 83,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def preprocess(corpus, cleaning = True, stemming = False, stem_type = None, lemmatization = False, remove_stopwords = True):\n",
        "    '''\n",
        "    Purpose : Function to perform all pre-processing tasks (cleaning, stemming, lemmatization, stopwords removal etc.)\n",
        "\n",
        "    Input :\n",
        "    'corpus' - Text corpus on which pre-processing tasks will be performed\n",
        "    'keep_list' - List of words to be retained during cleaning process\n",
        "    'cleaning', 'stemming', 'lemmatization', 'remove_stopwords' - Boolean variables indicating whether a particular task should\n",
        "                                                                  be performed or not\n",
        "    'stem_type' - Choose between Porter stemmer or Snowball(Porter2) stemmer. Default is \"None\", which corresponds to Porter\n",
        "                  Stemmer. 'snowball' corresponds to Snowball Stemmer\n",
        "\n",
        "    Note : Either stemming or lemmatization should be used. There's no benefit of using both of them together\n",
        "\n",
        "    Output : Returns the processed text corpus\n",
        "\n",
        "    '''\n",
        "\n",
        "    if cleaning == True:\n",
        "        corpus = text_clean(corpus)\n",
        "\n",
        "    if remove_stopwords == True:\n",
        "        corpus = stopwords_removal(corpus)\n",
        "    else :\n",
        "        corpus = [[x for x in x.split()] for x in corpus]\n",
        "\n",
        "    if lemmatization == True:\n",
        "        corpus = lemmatize(corpus)\n",
        "\n",
        "\n",
        "    if stemming == True:\n",
        "        corpus = stem(corpus, stem_type)\n",
        "\n",
        "    corpus = [' '.join(x) for x in corpus]\n",
        "\n",
        "    return corpus"
      ],
      "metadata": {
        "id": "XppfJyg9Z2hW"
      },
      "execution_count": 84,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data = preprocess(data)"
      ],
      "metadata": {
        "id": "Icoe2DP5Z4Y7"
      },
      "execution_count": 85,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "preprocessed_data = []\n",
        "for line in data:\n",
        "    if line != \"\":\n",
        "        preprocessed_data.append(line.split())"
      ],
      "metadata": {
        "id": "8yHppKV5Z6Tq"
      },
      "execution_count": 86,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# model.build_vocab(corpus_iterable=preprocessed_data)\n",
        "print(len(model.wv.key_to_index))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qgLHGkqaZ9QD",
        "outputId": "b9fe24f5-2aa6-4042-b38b-83d176a0d3b5"
      },
      "execution_count": 89,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "182228\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# model.train(corpus_iterable=preprocessed_data, total_examples=model.corpus_count, epochs=2)"
      ],
      "metadata": {
        "id": "2Ju3qV_obUkL"
      },
      "execution_count": 91,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.wv.most_similar('eplain', topn=5)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ucoa0o5gd4u4",
        "outputId": "a16ca6dc-b6a6-4ac6-90b1-f23fd4f6097f"
      },
      "execution_count": 92,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('which', 0.8329668641090393),\n",
              " ('articles', 0.7635992765426636),\n",
              " ('think', 0.6568771600723267),\n",
              " ('who', 0.42223498225212097),\n",
              " ('people', 0.36157968640327454)]"
            ]
          },
          "metadata": {},
          "execution_count": 92
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# model.wv.most_similar('reminder', topn=5)"
      ],
      "metadata": {
        "id": "LAcAcMbYejTt"
      },
      "execution_count": 94,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.wv.most_similar('relevnt', topn=5)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ar0u33lNelUh",
        "outputId": "aaa53f96-3a2e-47b0-dcd1-ee584ba35bbd"
      },
      "execution_count": 95,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('article', 0.6791090369224548),\n",
              " ('who', 0.6694713234901428),\n",
              " ('one', 0.5658158659934998),\n",
              " ('how', 0.5541751384735107),\n",
              " ('think', 0.45872461795806885)]"
            ]
          },
          "metadata": {},
          "execution_count": 95
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# # Function to preprocess sentences\n",
        "# def preprocess(sentence):\n",
        "#     # Add your preprocessing steps here\n",
        "#     return sentence.lower().split()  # Example: Lowercasing and tokenizing\n",
        "\n",
        "# # Calculate the vector representation of a sentence\n",
        "# def calculate_sentence_vector(tokens, model):\n",
        "#     vector = np.zeros(model.vector_size)\n",
        "#     count = 0\n",
        "#     for word in tokens:\n",
        "#         if word in model.wv:\n",
        "#             vector += model.wv[word]\n",
        "#             count += 1\n",
        "#     if count != 0:\n",
        "#         vector /= count\n",
        "#     return vector\n",
        "\n",
        "# # Calculate Word Mover's Distance\n",
        "# def word_mover_distance(sentence1, sentence2, model):\n",
        "#     tokens1 = preprocess(sentence1)\n",
        "#     tokens2 = preprocess(sentence2)\n",
        "#     vector1 = calculate_sentence_vector(tokens1, model)\n",
        "#     vector2 = calculate_sentence_vector(tokens2, model)\n",
        "#     return np.linalg.norm(vector1 - vector2)\n",
        "\n",
        "# # Example sentences\n",
        "# sentence1 = \"Obama speaks to the media in Illinois\"\n",
        "# sentence2 = \"President greets the press in Chicago\"\n",
        "# sentence3 = \"Apple is my favorite company\"\n",
        "\n",
        "# # Calculate Word Mover's Distance\n",
        "# distance = word_mover_distance(sentence1, sentence2, model)\n",
        "# print('Word Mover\\'s Distance:', distance)\n",
        "\n",
        "# # Calculate Word Mover's Distance\n",
        "# distance = word_mover_distance(sentence2, sentence3, model)\n",
        "# print('Word Mover\\'s Distance:', distance)"
      ],
      "metadata": {
        "id": "sn-jWGI-eonR"
      },
      "execution_count": 99,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow import keras\n",
        "import tensorflow as tf\n",
        "import tensorflow_hub as hub\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import os\n",
        "import pandas as pd\n",
        "import scipy.spatial\n",
        "\n",
        "#Loading pretrained model\n",
        "module_url = \"https://tfhub.dev/google/universal-sentence-encoder/4\"\n",
        "model = hub.load(module_url)\n",
        "print(\"Universal Sentence Encoder loaded from %s\" % module_url)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UZO2HK0lesH_",
        "outputId": "ab7769e8-af32-472c-eb83-9f838e12aefd"
      },
      "execution_count": 100,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Universal Sentence Encoder loaded from https://tfhub.dev/google/universal-sentence-encoder/4\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def embed(input):\n",
        "  return model (input)"
      ],
      "metadata": {
        "id": "81ev88iDe-Vn"
      },
      "execution_count": 101,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sentence = \"This is an example code to get embedding of a sentence.\"\n",
        "message_embeddings = embed([sentence])\n",
        "print(\"Message: {}\".format(sentence))\n",
        "print(\"Embedding size: {}\".format(len(message_embeddings[0])))\n",
        "message_embedding_snippet = \", \".join(str(x) for x in np.array(message_embeddings[0]).tolist()[:3])\n",
        "print(\"Embedding: [{}, ...]\\n\".format(message_embedding_snippet))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3PtpBvRCfB5N",
        "outputId": "fff03fa7-482a-4f96-9028-e22d6baea03c"
      },
      "execution_count": 102,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Message: This is an example code to get embedding of a sentence.\n",
            "Embedding size: 512\n",
            "Embedding: [0.041062358766794205, -0.01667184941470623, 0.013348660431802273, ...]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def similarity_measure(messages_):\n",
        "  message_embeddings_ = embed (messages_)\n",
        "  distancel = scipy.spatial.distance.cdist([message_embeddings_[0]], [message_embeddings_[1]], \"cosine\")[0]\n",
        "  print(\"Similarity score = {}\". format(1-distancel))"
      ],
      "metadata": {
        "id": "pQTP7ytxfDV4"
      },
      "execution_count": 103,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "messages = [\n",
        "\"how old are you?\",\n",
        "\"what is your age?\"\n",
        "]\n",
        "similarity_measure(messages)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PfUKVa4NfFIf",
        "outputId": "f6067087-ef6d-4faf-8e6b-aeda4979d274"
      },
      "execution_count": 104,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Similarity score = [0.80158678]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "JCu_EVNJfHMh"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}